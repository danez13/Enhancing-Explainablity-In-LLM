<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Documentation for training LSTM and CNN models for the e-SNLI dataset.">
    <title>Model Training Documentation for e-SNLI Dataset</title>
    <link rel="stylesheet" href="styles.css"> <!-- Link to your CSS stylesheet -->
</head>
<body>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="prereqs.html">prerequisites</a></li>
            <li>
                <a href="model.html">model</a>
                <ul>
                    <li><a href="data_loader.html">load dataset</a></li>
                    <li><a href="model_builder.html">build model</a></li>
                    <li><a href="saliency_utils.html">model saliency utilities</a></li>
                    <li><a href="train_cnn.html">train CNN model</a></li>
                </ul>
            </li>
            <li>
                <a href="saliency_gen.html">saliency generation</a>
                <ul>
                    <li><a href="generate_random_sal.html">generate random saliency values</a></li>
                    <li><a href="interpret_grads_occ.html">generate gradient and occlusion saliency values</a></li>
                    <li><a href="interpret_lime.html">generate lime values</a></li>
                    <li><a href="interpret_shap.html">generate shap values</a></li>
                </ul>
            </li>
            <li>
                <a href="saliency_eval.html">saliency evaluation</a>
                <ul>
                    <li><a href="confidence.html">confidence</a></li>
                    <li><a href="faithfulness.html">faithfulness</a></li>
                    <li><a href="human_agreement.html">human agreement</a></li>
                    <li><a href="consistency_precompute.html">precompute consistency</a></li>
                    <li><a href="consistency_rats.html">evaluate rational consistency</a></li>
                    <li><a href="consist_data_samples.html">consistent data sample pairs</a></li>
                    <li><a href="consist_data.html">data consistency</a></li>
                </ul>
            </li>
            <li><a href="analysis.html">analysis</a></li>
        </ul>
        <div class="hamburger">
            <span class="bar"></span>
            <span class="bar"></span>
            <span class="bar"></span>
        </div>
    </nav>

    <div class="container">
        <header>
            <h1>Model Training</h1>
            <p>This script trains CNN and LSTM models on the e-SNLI dataset for Natural Language Inference (NLI) tasks.</p>
        </header>
        <div class="section" id="overview">
            <h2>Overview</h2>
            <p>
                This Python script provides a framework for training both LSTM and CNN models on the e-SNLI (SNLI for e-commerce) dataset.
                The models are designed to predict the relationship between pairs of sentences in an NLI task: whether the premise entails, contradicts, or is neutral to the hypothesis.
            </p>
            <p>The script performs the following key operations:</p>
            <ul>
                <li>Loading and preprocessing the e-SNLI dataset.</li>
                <li>Setting up model architectures (CNN in this case).</li>
                <li>Training models using a specified number of epochs and batch sizes.</li>
                <li>Validating and evaluating models using accuracy and F1 scores.</li>
                <li>Implementing early stopping to prevent overfitting.</li>
            </ul>
        </div>

        <div class="section" id="usage">
            <h2>Usage</h2>
            <p>Run the script using Python:</p>
            <pre><code>python -m models.train_cnn</code></pre>
            <p>Configuration parameters can be modified within the script by editing the <code>args</code> dictionary. The script automatically trains the model using the specified configuration.</p>
            <h3>Key Features:</h3>
            <ul>
                <li>Training mode (train/test).</li>
                <li>Early stopping and dynamic learning rate adjustment based on validation performance.</li>
                <li>Save and load model checkpoints.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Functions</h2>

            <h3><code>train_model</code></h3>
            <p>Trains a model for a specified number of epochs using training and validation data loaders, optimizer, and scheduler.</p>
            <h4>Parameters:</h4>
            <ul class="parameters">
                <li><code>model</code>: <code>torch.nn.Module</code> - The model to be trained.</li>
                <li><code>train_dl</code>: <code>BatchSampler</code> - Training data loader.</li>
                <li><code>dev_dl</code>: <code>BatchSampler</code> - Validation data loader.</li>
                <li><code>optimizer</code>: <code>torch.optim.Optimizer</code> - The optimizer used for training.</li>
                <li><code>scheduler</code>: <code>torch.optim.lr_scheduler.LambdaLR</code> - The learning rate scheduler.</li>
                <li><code>n_epochs</code>: <code>int</code> - Number of epochs to train.</li>
                <li><code>early_stopping</code>: <code>EarlyStopping</code> - Early stopping instance for stopping training early based on performance.</li>
            </ul>
            <h4>Returns:</h4>
            <p><code>best_model_weights</code>: <code>Dict</code> - Best weights after training.<br>
            <code>best_val</code>: <code>Dict</code> - Performance metrics (e.g., validation F1 score).</p>

            <h3><code>eval_model</code></h3>
            <p>Evaluates a model on a given dataset, calculating loss and performance metrics like accuracy or F1 score.</p>
            <h4>Parameters:</h4>
            <ul class="parameters">
                <li><code>model</code>: <code>torch.nn.Module</code> - The model to be evaluated.</li>
                <li><code>test_dl</code>: <code>BucketBatchSampler</code> - Test data loader.</li>
                <li><code>measure</code>: <code>str</code> - Metric to compute ('acc' for accuracy, otherwise computes F1 score).</li>
            </ul>
            <h4>Returns:</h4>
            <p><code>p</code>: Precision score.<br>
            <code>r</code>: Recall score.<br>
            <code>f1</code>: F1 score.<br>
            <code>losses</code>: Mean loss of the evaluation.</p>

        </div>
    
        <div class="section" id="parameters">
            <h2>Parameters</h2>
            <p>The script accepts several parameters in the <code>args</code> dictionary for fine-tuning the training process. Below is a list of the most important parameters:</p>
            <ul>
                <li><strong>gpu</strong>: Whether to use GPU for training (True/False).</li>
                <li><strong>init_only</strong>: Set to True to only initialize the model (useful for testing or loading a pre-trained model).</li>
                <li><strong>seed</strong>: Random seed for reproducibility.</li>
                <li><strong>labels</strong>: Number of output classes (e.g., 3 for entailment, contradiction, neutral).</li>
                <li><strong>dataset_dir</strong>: Path to the e-SNLI dataset.</li>
                <li><strong>batch_size</strong>: The batch size used for training.</li>
                <li><strong>lr</strong>: Learning rate for the AdamW optimizer.</li>
                <li><strong>epochs</strong>: The number of epochs for training.</li>
                <li><strong>patience</strong>: Early stopping patience parameter.</li>
                <li><strong>model</strong>: Specifies the model type (e.g., CNN).</li>
                <li><strong>embedding_dim</strong>: Word embedding dimension (300 for GloVe embeddings).</li>
            </ul>
        </div>

        <div class="section">
            <h2>Model Setup and Training</h2>
            <p>The training loop follows this process:</p>
            <ul>
                <li>Initialize the model (CNN) and set random seed for reproducibility.</li>
                <li>Load the training and validation datasets using the <code>NLIDataset</code> class.</li>
                <li>Set up the optimizer (<code>AdamW</code>) and learning rate scheduler (<code>ReduceLROnPlateau</code>).</li>
                <li>Train the model using the <code>train_model</code> function for a specified number of epochs, applying early stopping if necessary.</li>
                <li>Save the model checkpoint once training completes.</li>
            </ul>
            <p>Once trained, the best model weights and performance metrics are saved to the specified model path for future use.</p>
        </div>
    
        <div class="section" id="evaluation">
            <h2>Evaluation</h2>
            <p>The script evaluates model performance using the following metrics:</p>
            <ul>
                <li><strong>Accuracy</strong>: Measures the proportion of correct predictions.</li>
                <li><strong>F1-Score</strong>: A balance between precision and recall, especially useful for imbalanced datasets.</li>
                <li><strong>Confusion Matrix</strong>: Provides a detailed breakdown of model predictions versus actual labels.</li>
            </ul>
            <p>Evaluation is performed at the end of each epoch during training, and the best-performing model (based on validation F1 score) is saved as a checkpoint.</p>
        </div>
        <script src="script.js"></script>
    </div>
</body>
</html>
