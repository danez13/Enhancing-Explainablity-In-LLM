<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dataset and Collate Functions Documentation</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="prereqs.html">prerequisites</a></li>
            <li>
                <a href="model.html">model</a>
                <ul>
                    <li><a href="data_loader.html">load dataset</a></li>
                    <li><a href="model_builder.html">build model</a></li>
                    <li><a href="saliency_utils.html">model saliency utilities</a></li>
                    <li><a href="train_cnn.html">train CNN model</a></li>
                </ul>
            </li>
            <li>
                <a href="saliency_gen.html">saliency generation</a>
                <ul>
                    <li><a href="generate_random_sal.html">generate random saliency values</a></li>
                    <li><a href="interpret_grads_occ.html">generate gradient and occlusion saliency values</a></li>
                    <li><a href="interpret_lime.html">generate lime values</a></li>
                    <li><a href="interpret_shap.html">generate shap values</a></li>
                </ul>
            </li>
            <li>
                <a href="saliency_eval.html">saliency evaluation</a>
                <ul>
                    <li><a href="confidence.html">confidence</a></li>
                    <li><a href="faithfulness.html">faithfulness</a></li>
                    <li><a href="human_agreement.html">human agreement</a></li>
                    <li><a href="consistency_precompute.html">precompute consistency</a></li>
                    <li><a href="consistency_rats.html">evaluate rational consistency</a></li>
                    <li><a href="consist_data_samples.html">consistent data sample pairs</a></li>
                    <li><a href="consist_data.html">data consistency</a></li>
                </ul>
            </li>
            <li><a href="analysis.html">analysis</a></li>
        </ul>
        <div class="hamburger">
            <span class="bar"></span>
            <span class="bar"></span>
            <span class="bar"></span>
        </div>
    </nav>
    <div class="container">
        <h1>Dataset loader</h1>
        <p>This module provides custom datasets, samplers, and collate functions for natural language inference (NLI) models. It includes utilities for handling token saliency and batching operations to enhance model training and evaluation.</p>

        <div class="section">
            <h2>Functions</h2>

            <h3><code>collate_threshold</code></h3>
            <p>Applies a saliency-based threshold to mask tokens in input sequences. Utilizes an existing collate function to prepare the batch and then modifies it based on token saliency.</p>
            <h4>Parameters:</h4>
            <ul class="parameters">
                <li><code>instances</code>: List[Dict] - Input data instances.</li>
                <li><code>tokenizer</code>: <code>PreTrainedTokenizer</code> - Tokenizer for converting text to IDs.</li>
                <li><code>return_attention_masks</code>: bool - Whether to return attention masks.</li>
                <li><code>pad_to_max_length</code>: bool - Whether to pad sequences to a fixed length.</li>
                <li><code>device</code>: str - Device to use (e.g., 'cuda').</li>
                <li><code>collate_orig</code>: callable - Original collate function.</li>
                <li><code>threshold</code>: float - Threshold percentage for token masking.</li>
                <li><code>n_classes</code>: int - Number of saliency classes.</li>
            </ul>
            <h4>Returns:</h4>
            <p>List[torch.Tensor] - Modified batch with masked tokens.</p>

            <h3><code>collate_nli</code></h3>
            <p>Standard collate function for tokenizing and batching NLI instances. Handles tokenization, padding, and attention mask creation.</p>
            <h4>Parameters:</h4>
            <ul class="parameters">
                <li><code>instances</code>: List[Dict] - Input data instances.</li>
                <li><code>tokenizer</code>: <code>PreTrainedTokenizer</code> - Tokenizer for converting text to IDs.</li>
                <li><code>return_attention_masks</code>: bool - Whether to return attention masks.</li>
                <li><code>pad_to_max_length</code>: bool - Whether to pad sequences to a fixed length.</li>
                <li><code>device</code>: str - Device to use (e.g., 'cuda').</li>
            </ul>
            <h4>Returns:</h4>
            <p>List[torch.Tensor] - Batch with tokenized inputs, attention masks, and labels.</p>
        </div>

        <div class="section">
            <h2>Classes</h2>

            <h3><code>SortedSampler</code></h3>
            <p>A custom sampler that sorts data by a specified key and returns indices for iteration.</p>
            <h4>Methods:</h4>
            <ul>
                <li><code>__iter__</code>: Iterator over sorted indices.</li>
                <li><code>__len__</code>: Returns the number of samples.</li>
            </ul>

            <h3><code>BucketBatchSampler</code></h3>
            <p>Combines random sampling with sorted batching to organize data into buckets based on sequence length, improving batch efficiency.</p>
            <h4>Methods:</h4>
            <ul>
                <li><code>__iter__</code>: Iterator over batches.</li>
                <li><code>__len__</code>: Returns the number of batches.</li>
            </ul>

            <h3><code>DatasetSaliency</code></h3>
            <p>Extends the original dataset by appending saliency data to each instance.</p>
            <h4>Attributes:</h4>
            <ul>
                <li><code>_dataset_cls</code>: Original dataset class.</li>
                <li><code>_dataset</code>: Saliency-enhanced dataset.</li>
            </ul>

            <h3><code>NLIDataset</code></h3>
            <p>Custom dataset class for loading and processing e-SNLI data.</p>
            <h4>Attributes:</h4>
            <ul>
                <li><code>_PATHS</code>: Dict of dataset paths (train/dev/test).</li>
                <li><code>_dataset</code>: Loaded dataset instances.</li>
            </ul>
            <h4>Methods:</h4>
            <ul>
                <li><code>__getitem__</code>: Returns a tuple of premise, hypothesis, label, and optional salient features.</li>
                <li><code>__len__</code>: Returns the dataset length.</li>
            </ul>
        </div>
    </div>
    <script src="script.js"></script>
</body>
</html>
