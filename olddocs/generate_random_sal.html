<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Documentation for generating random saliency scores for baseline models.">
    <title>Random Saliency Score Generation - Documentation</title>
    <link rel="stylesheet" href="styles.css"> <!-- Link to your CSS stylesheet -->
</head>
<body>
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="prereqs.html">prerequisites</a></li>
            <li>
                <a href="model.html">model</a>
                <ul>
                    <li><a href="data_loader.html">load dataset</a></li>
                    <li><a href="model_builder.html">build model</a></li>
                    <li><a href="saliency_utils.html">model saliency utilities</a></li>
                    <li><a href="train_cnn.html">train CNN model</a></li>
                </ul>
            </li>
            <li>
                <a href="saliency_gen.html">saliency generation</a>
                <ul>
                    <li><a href="generate_random_sal.html">generate random saliency values</a></li>
                    <li><a href="interpret_grads_occ.html">generate gradient and occlusion saliency values</a></li>
                    <li><a href="interpret_lime.html">generate lime values</a></li>
                    <li><a href="interpret_shap.html">generate shap values</a></li>
                </ul>
            </li>
            <li>
                <a href="saliency_eval.html">saliency evaluation</a>
                <ul>
                    <li><a href="confidence.html">confidence</a></li>
                    <li><a href="faithfulness.html">faithfulness</a></li>
                    <li><a href="human_agreement.html">human agreement</a></li>
                    <li><a href="consistency_precompute.html">precompute consistency</a></li>
                    <li><a href="consistency_rats.html">evaluate rational consistency</a></li>
                    <li><a href="consist_data_samples.html">consistent data sample pairs</a></li>
                    <li><a href="consist_data.html">data consistency</a></li>
                </ul>
            </li>
            <li><a href="analysis.html">analysis</a></li>
        </ul>
        <div class="hamburger">
            <span class="bar"></span>
            <span class="bar"></span>
            <span class="bar"></span>
        </div>
    </nav>

    <div class="container">
        <header>
            <h1>Random Saliency Score Generation</h1>
            <p>This script generates random saliency scores as a baseline for comparison with other saliency methods.</p>
        </header>

        <div class="section" id="overview">
            <h2>Overview</h2>
            <p>
                This script processes precomputed saliency files, replaces their values with random scores, and saves the results for further evaluation. 
                It supports multiple saliency methods and models while ensuring reproducibility through fixed random seeds.
            </p>
        </div>

        <div class="section" id="usage">
            <h2>Usage</h2>
            <p>Run the script to generate random saliency scores:</p>
            <pre><code>python -m saliency_gen.generate_random_saliency</code></pre>
            <h3>Key Features:</h3>
            <ul>
                <li>Processes multiple saliency methods and model checkpoints.</li>
                <li>Generates random scores for each token in the saliency map.</li>
                <li>Ensures reproducibility through fixed random seeds.</li>
                <li>Tracks and reports computational FLOPs (time per sample).</li>
            </ul>
        </div>

        <div class="section" id="parameters">
            <h2>Parameters</h2>
            <p>The script uses a predefined argument dictionary to configure the process:</p>
            <ul>
                <li><strong>saliencies</strong>: List of saliency methods (e.g., "shap", "lime", "occlusion").</li>
                <li><strong>output_path</strong>: List of base output paths for saving saliency scores.</li>
                <li><strong>seed</strong>: Random seed for reproducibility.</li>
                <li><strong>labels</strong>: Number of output classes (e.g., 3 for entailment, contradiction, neutral).</li>
            </ul>
        </div>

        <div class="section" id="execution">
            <h2>Execution Flow</h2>
            <ol>
                <li>Set up the random seed to ensure reproducibility.</li>
                <li>Iterate over all saliency methods, models, and output paths.</li>
                <li>For each instance in the saliency file:
                    <ul>
                        <li>Parse the JSON object for token-level saliency data.</li>
                        <li>Replace saliency scores with random values for each token and class.</li>
                        <li>Write the modified data back to the output file.</li>
                    </ul>
                </li>
                <li>Measure and log the mean and standard deviation of FLOPs for each configuration.</li>
            </ol>
        </div>

        <div class="section" id="evaluation">
            <h2>Evaluation</h2>
            <p>The script evaluates performance by tracking FLOPs (floating-point operations per second). The average and standard deviation are reported to analyze the computational cost of the random saliency generation process.</p>
        </div>

        <script src="script.js"></script>
    </div>
</body>
</html>
